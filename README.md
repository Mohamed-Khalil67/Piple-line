# Project Introduction : Pipeline Data GCP " Cloud Computing "

## Setps For solving a data analyzing and Cleaning in an elborated Way

- Collecting Data

- API Project Architecture Tree 

- API developpement 

- Docker Packaging 

- A Clear Documentation

## Collecting Data :

### Data analyzing and cleaning is done here by multiple Steps :-

Classification of the file utils.py

1 - Data Handling : 

2 - Feature Recipe :

3 - Feature Extractor : 

4 - ModelBuilder : 

5 - DataManager : 

### API Architecture Tree :-

ml_template_api

- ├── main.py
- ├── requirements.txt
- ├── Dockerfile
- └── ml
    - - ├── __init__.py
      │
    - - ├── model.joblib
      │
    - - ├── EDA.ipynb
      │
    - - ├── algo_pipeline_demo.ipynb
      │
    - - └── model.py
      │
    - -└── utils
      │
    - -├── __init__.py
      │
    - - └── utils.py
  
 ###
      



